{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03927d52-7cae-4704-9eb1-5e3fcb745107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cc76c-59e3-4376-aa52-1fcbbc1101c9",
   "metadata": {},
   "source": [
    "## Combining base indices for pruning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8f77d4-0cba-4d99-888e-47493adb50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_main = '' # where we save all main paths\n",
    "dir_base_eval_refs = ''  # where we saved path chunks of datapoints to prune\n",
    "eval_datasets = ['imagenet-a', 'imagenet-r', 'imagenet-v2', 'objectnet-subsample', 'imagenet-sketch', 'imagenet-val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74bb8fb3-71c0-4174-a8d7-bfd664bfa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_200m = np.load(dir_main+'paths_200m.npy')\n",
    "paths = {}\n",
    "sims = {}\n",
    "labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc4ca9e8-4065-4363-bd19-74cfcca4f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet-a done in 8.490407228469849s\n",
      "imagenet-r done in 4.347375869750977s\n",
      "imagenet-v2 done in 5.291475534439087s\n",
      "objectnet-subsample done in 6.13672399520874s\n",
      "imagenet-sketch done in 6.266106128692627s\n",
      "imagenet-val done in 2.8996026515960693s\n"
     ]
    }
   ],
   "source": [
    "# combine all paths, sims, labels for datapoints to prune for each eval dataset\n",
    "\n",
    "for ed in eval_datasets:\n",
    "    start_time = time.time()\n",
    "    paths[ed] = []\n",
    "    sims[ed] = []\n",
    "    labels[ed] = []\n",
    "    #ids_violation[ed] = []\n",
    "    # load all\n",
    "    for i in range(200):\n",
    "        paths[ed].append(np.load(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_paths_'+str(i)+'.npy'))\n",
    "        sims_temp = np.load(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_sims_'+str(i)+'.npy')\n",
    "        sims[ed].append(sims_temp)\n",
    "        labels[ed].append(np.load(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_labels_'+str(i)+'.npy'))\n",
    "    \n",
    "    # concatenate and sort\n",
    "    paths[ed] = np.concatenate(paths[ed])\n",
    "    sims[ed] = np.concatenate(sims[ed])\n",
    "    labels[ed] = np.concatenate(labels[ed])\n",
    "\n",
    "    idcs_sorted = np.argsort(paths[ed])\n",
    "    paths[ed] = paths[ed][idcs_sorted]\n",
    "    sims[ed] = sims[ed][idcs_sorted]\n",
    "    print(f\"{ed} done in {time.time()-start_time}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1034299-eedc-423a-96d9-60d3d24c2e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet-a, size = 138852\n",
      "imagenet-r, size = 5735749\n",
      "imagenet-v2, size = 274325\n",
      "objectnet-subsample, size = 266025\n",
      "imagenet-sketch, size = 8342783\n",
      "imagenet-val, size = 377340\n"
     ]
    }
   ],
   "source": [
    "for ed in eval_datasets:\n",
    "    print(f\"{ed}, size = {len(paths[ed])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c86b059-6b4a-4b7e-b0f2-9a8918b4f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save overall paths/sims/labels\n",
    "for ed in eval_datasets:\n",
    "    np.save(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_paths.npy', paths[ed])\n",
    "    np.save(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_sims.npy', sims[ed])\n",
    "    np.save(dir_base_eval_refs+'laion_'+ed+'/sims_per_query/overall_nn_labels.npy', labels[ed])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522773b-e14d-442c-9d59-44917d50f3df",
   "metadata": {},
   "source": [
    "## Generate all pruned dataset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2cabc-cc20-47e8-8686-f725a1560054",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_paths_200m = set(paths_200m)\n",
    "dict_names = {'imagenet-a': 'a', 'imagenet-r': 'r', 'imagenet-v2': 'v2', 'objectnet-subsample': 'objectnet',\n",
    "              'imagenet-sketch':'sketch', 'imagenet-val':'val'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b9fe2-7e13-41fb-848b-fa7d0d4d81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ed in eval_datasets:\n",
    "    paths_lo = np.array(list(set_paths_200m - set(paths[ed])))\n",
    "    paths_lo = np.sort(paths_lo)\n",
    "    assert print(len(paths[ed])+len(paths_lo) == len(paths_200m))\n",
    "    np.save(dir_main+'paths_pruned_'+dict_names[ed]+'_per_query_200m.npy', paths_lo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead3e52-9236-410e-a4fd-0e3ef2dc04f9",
   "metadata": {},
   "source": [
    "## Generate combined pruned dataset indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65570a0c-1664-4ebf-85ea-9dc95635222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the combined set of all paths to prune\n",
    "\n",
    "set_combined = set()\n",
    "for ed in eval_datasets:\n",
    "    set_combined = set_combined | set(paths[ed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f2a5b-e468-4016-a41e-4cbbd8ea24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and get it as an array\n",
    "paths_comb = np.array(list(set_combined))\n",
    "paths_comb = np.sort(np.unique(paths_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3ad1e-c9aa-4431-a0fc-3eb5a105168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined pruned paths paths\n",
    "paths_lo_combined = np.sort(np.array(list(set_paths_200m - set_combined)))\n",
    "np.save(dir_main+'paths_pruned_combined_per_query.npy', paths_lo_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48cbf4-2a78-4a77-a182-29db0265753f",
   "metadata": {},
   "source": [
    "## Throwing away random datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe32522-b7b9-4aa4-9608-5cac2a7fea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = {'175m':175000000, '150m':150000000, '125m':125000000, '100m':100000000, '75m':75000000, '50m':50000000}\n",
    "for size in sizes.keys():\n",
    "    idcs_lo_rand = random.sample(range(len(paths_200m)), sizes[size])\n",
    "    idcs_lo_rand = np.sort(np.unique(idcs_lo_rand))\n",
    "    print(len(idcs_lo_rand))\n",
    "    np.save(dir_main+'paths_pruned_rand_'+size+'.npy', paths_200m[idcs_lo_rand])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb0c0e-b204-4212-a3b8-164b0d34714f",
   "metadata": {},
   "source": [
    "## Throwing away FAR points and NEAR points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dcb556-ccbf-44e1-947b-1c57f905ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_max_laion = ''  # directory where max sims for each laion200m chunk and eval dataset is stored\n",
    "\n",
    "sims_max  = {}\n",
    "idcs_max  = {}\n",
    "for ed in eval_datasets:\n",
    "    sims_max[ed] = np.load(dir_max_laion+ed+'/sims_all.npy')\n",
    "    idcs_max[ed] = np.load(dir_max_laion+ed+'/idcs_all.npy')\n",
    "    \n",
    "    idcs_sorted = np.argsort(sims_max[ed])\n",
    "    sims_max[ed] = sims_max[ed][idcs_sorted]\n",
    "    idcs_max[ed] = idcs_max[ed][idcs_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7ae1f-fd17-465a-bfc8-87c27980798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all near and far pruned paths\n",
    "\n",
    "sizes = {'175m':175000000, '150m':150000000, '125m':125000000, '100m':100000000, '75m':75000000, '50m':50000000, '40m':40000000, '25m':25000000}\n",
    "\n",
    "idcs_far = {}\n",
    "idcs_near = {}\n",
    "\n",
    "for ed in eval_datasets:\n",
    "    idcs_far[ed] = {}\n",
    "    idcs_near[ed] = {}\n",
    "    for key in sizes.keys():\n",
    "        idcs_sorted_reverse = idcs_max[ed][::-1]\n",
    "        idcs_far[ed][key] = idcs_sorted_reverse[:sizes[key]]\n",
    "        idcs_near[ed][key] = idcs_max[ed][:sizes[key]]\n",
    "        \n",
    "        np.save(dir_main+'paths_pruned_far_'+dict_names[ed]+'_'+key+'.npy', idcs_far[ed][key])\n",
    "        np.save(dir_main+'paths_pruned_near_'+dict_names[ed]+'_'+key+'.npy', idcs_near[ed][key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
